{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from transformers import GPT2Tokenizer, GPT2Config\n",
    "from LLMHeadModelWithFFNOutput import LLMHeadModelWithFFNOutput\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ConfiguraciÃ³n del modelo y el tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "config = GPT2Config.from_pretrained('gpt2')\n",
    "num_layers = config.n_layer\n",
    "num_neurons = config.hidden_size * 4\n",
    "max_length = 19\n",
    "index_number = -3\n",
    "test_file = os.path.join('datasets', 'test_dataset.txt')\n",
    "folder = os.path.join('experiments', \"activations\")\n",
    "file = os.path.join(folder, \"gpt2.pickle\")\n",
    "model = LLMHeadModelWithFFNOutput.from_pretrained('gpt2-finetuned', config=config)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_file, encoding=\"utf-8\") as file:\n",
    "    text = file.readlines()\n",
    "\n",
    "prompts = [t[:index_number].strip() for t in text]\n",
    "numbers = [t[index_number:].strip() for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, prompts: list, numbers: list) -> float:\n",
    "    accuracy = 0\n",
    "    activations = []\n",
    "    for prompt, number in tqdm(zip(prompts, numbers), desc=\"Testing...\"):\n",
    "        input_ids = torch.tensor([tokenizer.encode(prompt)]).to(device)\n",
    "        outputs_tokens = model.generate(input_ids, max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n",
    "        output_text = tokenizer.decode(outputs_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "        output_text = output_text[index_number:].strip()\n",
    "\n",
    "        activation_ffn = model.get_activation_ffn()\n",
    "\n",
    "        if output_text == number:\n",
    "            activations.append(activation_ffn)\n",
    "            accuracy += 1\n",
    "\n",
    "    return accuracy * 100 / len(prompts), activations\n",
    "\n",
    "def get_activation_ffn(model, prompts: list) -> list:\n",
    "    activations = []\n",
    "    for prompt in tqdm(prompts, desc=\"Getting activations...\"):\n",
    "        input_ids = torch.tensor([tokenizer.encode(prompt)]).to(device)\n",
    "        _ = model.generate(input_ids, max_length=max_length, pad_token_id=tokenizer.eos_token_id)\n",
    "        activation_ffn = model.get_activation_ffn()\n",
    "        activations.append(activation_ffn)\n",
    "\n",
    "    activation_ffn_array = activations\n",
    "\n",
    "    return activation_ffn_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing...: 1000it [00:30, 32.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc, activations = get_accuracy(model, prompts, numbers)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_ffn_array = np.stack(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 12, 1, 1, 3072)\n"
     ]
    }
   ],
   "source": [
    "print(activation_ffn_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 297, 3072)\n"
     ]
    }
   ],
   "source": [
    "# reshape\n",
    "activation_ffn_array = activation_ffn_array.reshape(num_layers, -1, num_neurons)\n",
    "print(activation_ffn_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open(\"gpt2.pickle\", 'wb') as f:\n",
    "    pickle.dump(activation_ffn_array, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_low_activations_neuron_per_layer(activations: np.array, layer: int, threshold: float = 0.3, n_components: int = 10) -> tuple:\n",
    "    first_layer_activations = activations[layer]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_activations = scaler.fit_transform(first_layer_activations.reshape(-1, first_layer_activations.shape[-1])).reshape(first_layer_activations.shape)\n",
    "\n",
    "    nmf = NMF(n_components=n_components, max_iter=1000, random_state=0)\n",
    "    w = nmf.fit_transform(normalized_activations.reshape(-1, normalized_activations.shape[-1]))  # Aplana las activaciones para NMF\n",
    "    h = nmf.components_\n",
    "    \n",
    "    low_contribution_neurons = np.where(h.mean(axis=0) < threshold)[0]\n",
    "\n",
    "    return low_contribution_neurons, w, h\n",
    "\n",
    "def plot_w_and_h_heatmaps(w: np.array, h: np.array, layer: int):\n",
    "    # Mapa de calor para W\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(w, cmap='viridis')\n",
    "    plt.title('W Heatmap - Layer {}'.format(layer))\n",
    "    plt.xlabel('Components')\n",
    "    plt.ylabel('Tokens/Samples')\n",
    "    plt.show()\n",
    "\n",
    "    # Mapa de calor para H\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(h, cmap='viridis')\n",
    "    plt.title('H Heatmap - Layer {}'.format(layer))\n",
    "    plt.xlabel('Neurons')\n",
    "    plt.ylabel('Components')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 0 Number of pruned neurons: 438\n",
      "Layer: 1 Number of pruned neurons: 1559\n",
      "Layer: 2 Number of pruned neurons: 492\n",
      "Layer: 3 Number of pruned neurons: 1055\n",
      "Layer: 4 Number of pruned neurons: 522\n",
      "Layer: 5 Number of pruned neurons: 880\n",
      "Layer: 6 Number of pruned neurons: 491\n",
      "Layer: 7 Number of pruned neurons: 581\n",
      "Layer: 8 Number of pruned neurons: 986\n",
      "Layer: 9 Number of pruned neurons: 721\n",
      "Layer: 10 Number of pruned neurons: 764\n",
      "Layer: 11 Number of pruned neurons: 783\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_layers):\n",
    "    high_contribution_neurons, w, h = get_low_activations_neuron_per_layer(activation_ffn_array, i)\n",
    "    print(\"Layer:\", i, \"Number of pruned neurons:\", activation_ffn_array.shape[-1] - len(high_contribution_neurons))\n",
    "    #plot_w_and_h_heatmaps(w, h, i) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
