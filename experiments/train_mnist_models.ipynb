{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "principal_path = '../'\n",
    "if principal_path not in sys.path:\n",
    "    sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from models.MNISTModel import MNISTModel\n",
    "from models.MNISTModelWithBottelNeck import MNISTModelWithBottelNeck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 2024\n",
    "pl.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "LEARING_RATE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "FOLDER_CHEKPOINTS = 'checkpoints'\n",
    "FOLDER_ACTIVATIONS = 'activations'\n",
    "print(f'Using {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_parameters(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    unit_scale = {\n",
    "        '': 1,\n",
    "        'K': 10 ** 3,\n",
    "        'M': 10 ** 6,\n",
    "        'B': 10 ** 9\n",
    "    }\n",
    "    for unit, scale in sorted(unit_scale.items(), key=lambda x: x[1], reverse=True):\n",
    "        if num_params >= scale:\n",
    "            return f'{round(num_params / scale, 1)}{unit}'\n",
    "    return str(num_params)\n",
    "\n",
    "def log_csv(model, model_name, folder = 'csv_logs'):\n",
    "    number_of_parameters = get_number_of_parameters(model)\n",
    "    return CSVLogger(\n",
    "        save_dir=folder,\n",
    "        name=f\"{model_name}_{number_of_parameters}\",\n",
    "    )\n",
    "\n",
    "def log_tensorboard(model, model_name, folder = 'tb_logs'):\n",
    "    number_of_parameters = get_number_of_parameters(model)\n",
    "    return TensorBoardLogger(\n",
    "        save_dir=folder,\n",
    "        name=f\"{model_name}_{number_of_parameters}\",\n",
    "    )\n",
    "\n",
    "def log_wandb(model, model_name, folder = 'wandb_logs'):\n",
    "    number_of_parameters = get_number_of_parameters(model)\n",
    "    return WandbLogger(\n",
    "        save_dir=folder,\n",
    "        name=f\"{model_name}_{number_of_parameters}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=BATCH_SIZE, num_workers=4):\n",
    "    # Transformaciones para los datos\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # Carga de datos de entrenamiento\n",
    "    mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
    "    \n",
    "    # División entre entrenamiento y validación\n",
    "    train_size = int(0.8 * len(mnist_train))\n",
    "    val_size = len(mnist_train) - train_size\n",
    "    mnist_train, mnist_val = random_split(mnist_train, [train_size, val_size])\n",
    "\n",
    "    # DataLoader para entrenamiento y validación\n",
    "    train_loader = DataLoader(mnist_train, batch_size=batch_size, num_workers=num_workers, shuffle=True, persistent_workers=True)\n",
    "    val_loader = DataLoader(mnist_val, batch_size=batch_size, num_workers=num_workers, shuffle=False, persistent_workers=True)\n",
    "\n",
    "    # Carga de datos de test\n",
    "    mnist_test = MNIST(os.getcwd(), train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=batch_size, num_workers=num_workers, persistent_workers=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel(lr=LEARING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggers = [\n",
    "    #log_tensorboard(model, 'MLP'),\n",
    "    log_csv(model, 'MLP'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params\n",
      "--------------------------------------------------\n",
      "0 | train_acc | MulticlassAccuracy  | 0     \n",
      "1 | val_acc   | MulticlassAccuracy  | 0     \n",
      "2 | test_acc  | MulticlassAccuracy  | 0     \n",
      "3 | precision | MulticlassPrecision | 0     \n",
      "4 | recall    | MulticlassRecall    | 0     \n",
      "5 | f1        | MulticlassF1Score   | 0     \n",
      "6 | layer_1   | Linear              | 100 K \n",
      "7 | layer_2   | Linear              | 33.0 K\n",
      "8 | layer_3   | Linear              | 2.6 K \n",
      "--------------------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: |          | 0/? [00:00<?, ?it/s]                                 Failed to save model graph: 'ExperimentWriter' object has no attribute 'add_graph'\n",
      "Epoch 0: 100%|██████████| 750/750 [00:03<00:00, 211.45it/s, v_num=1, train_loss=0.202, train_acc=0.922, val_loss=0.168, val_acc=0.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to save weights histogram: 'ExperimentWriter' object has no attribute 'add_histogram'\n",
      "Epoch 0: 100%|██████████| 750/750 [00:03<00:00, 211.07it/s, v_num=1, train_loss=0.202, train_acc=0.922, val_loss=0.168, val_acc=0.950]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS, logger=loggers)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:00<00:00, 219.24it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "           f1               0.9464820027351379\n",
      "        precision           0.9515219926834106\n",
      "         recall             0.9501408934593201\n",
      "        test_acc            0.9519000053405762\n",
      "        test_loss           0.15671443939208984\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.15671443939208984,\n",
       "  'test_acc': 0.9519000053405762,\n",
       "  'precision': 0.9515219926834106,\n",
       "  'recall': 0.9501408934593201,\n",
       "  'f1': 0.9464820027351379}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save checkpoint\n",
    "file = os.path.join(FOLDER_CHEKPOINTS, 'mnist_model.ckpt')\n",
    "trainer.save_checkpoint(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottel_neck_model = MNISTModelWithBottelNeck(lr=LEARING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggers = [\n",
    "    #log_tensorboard(bottel_neck_model, 'BottelNeck'),\n",
    "    log_csv(bottel_neck_model, 'BottelNeck'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Neither `tensorboard` nor `tensorboardX` is available. Try `pip install`ing either.\nDistributionNotFound: The 'tensorboardX' distribution was not found and is required by the application. HINT: Try running `pip install -U 'tensorboardX'`\nDistributionNotFound: The 'tensorboard' distribution was not found and is required by the application. HINT: Try running `pip install -U 'tensorboard'`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39mEPOCHS, logger\u001b[38;5;241m=\u001b[39m\u001b[43mlog_tensorboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbottel_neck_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBottelNeck\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(bottel_neck_model, train_loader, val_loader)\n",
      "Cell \u001b[1;32mIn[36], line 23\u001b[0m, in \u001b[0;36mlog_tensorboard\u001b[1;34m(model, model_name, folder)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_tensorboard\u001b[39m(model, model_name, folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtb_logs\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     22\u001b[0m     number_of_parameters \u001b[38;5;241m=\u001b[39m get_number_of_parameters(model)\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorBoardLogger\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnumber_of_parameters\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\code\\ExAI\\exai\\lib\\site-packages\\pytorch_lightning\\loggers\\tensorboard.py:97\u001b[0m, in \u001b[0;36mTensorBoardLogger.__init__\u001b[1;34m(self, save_dir, name, version, log_graph, default_hp_metric, prefix, sub_dir, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     88\u001b[0m     save_dir: _PATH,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     96\u001b[0m ):\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     98\u001b[0m         root_dir\u001b[38;5;241m=\u001b[39msave_dir,\n\u001b[0;32m     99\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    100\u001b[0m         version\u001b[38;5;241m=\u001b[39mversion,\n\u001b[0;32m    101\u001b[0m         default_hp_metric\u001b[38;5;241m=\u001b[39mdefault_hp_metric,\n\u001b[0;32m    102\u001b[0m         prefix\u001b[38;5;241m=\u001b[39mprefix,\n\u001b[0;32m    103\u001b[0m         sub_dir\u001b[38;5;241m=\u001b[39msub_dir,\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    105\u001b[0m     )\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m log_graph \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _TENSORBOARD_AVAILABLE:\n\u001b[0;32m    107\u001b[0m         rank_zero_warn(\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou set `TensorBoardLogger(log_graph=True)` but `tensorboard` is not available.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(_TENSORBOARD_AVAILABLE)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         )\n",
      "File \u001b[1;32mc:\\code\\ExAI\\exai\\lib\\site-packages\\lightning_fabric\\loggers\\tensorboard.py:93\u001b[0m, in \u001b[0;36mTensorBoardLogger.__init__\u001b[1;34m(self, root_dir, name, version, default_hp_metric, prefix, sub_dir, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     84\u001b[0m     root_dir: _PATH,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     91\u001b[0m ):\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _TENSORBOARD_AVAILABLE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _TENSORBOARDX_AVAILABLE:\n\u001b[1;32m---> 93\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeither `tensorboard` nor `tensorboardX` is available. Try `pip install`ing either.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(_TENSORBOARDX_AVAILABLE)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(_TENSORBOARD_AVAILABLE)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     98\u001b[0m     root_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(root_dir)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: Neither `tensorboard` nor `tensorboardX` is available. Try `pip install`ing either.\nDistributionNotFound: The 'tensorboardX' distribution was not found and is required by the application. HINT: Try running `pip install -U 'tensorboardX'`\nDistributionNotFound: The 'tensorboard' distribution was not found and is required by the application. HINT: Try running `pip install -U 'tensorboard'`"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS, logger=log_tensorboard(bottel_neck_model, 'BottelNeck'))\n",
    "trainer.fit(bottel_neck_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865808cb633c46078638e70e6ee8ee66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            f1             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9632332921028137     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9670910835266113     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9658780097961426     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9684000015258789     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10720314830541611    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           f1            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9632332921028137    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9670910835266113    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9658780097961426    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9684000015258789    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10720314830541611   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.10720314830541611,\n",
       "  'test_acc': 0.9684000015258789,\n",
       "  'precision': 0.9670910835266113,\n",
       "  'recall': 0.9658780097961426,\n",
       "  'f1': 0.9632332921028137}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(bottel_neck_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save checkpoint\n",
    "file = os.path.join(FOLDER_CHEKPOINTS, 'mnist_model_bottel_neck.ckpt')\n",
    "trainer.save_checkpoint(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_activations():\n",
    "    # load only one image of the test set\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_test = MNIST(os.getcwd(), train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=1, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "test_loader_act = load_data_for_activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTModel(\n",
       "  (train_acc): MulticlassAccuracy()\n",
       "  (val_acc): MulticlassAccuracy()\n",
       "  (test_acc): MulticlassAccuracy()\n",
       "  (precision): MulticlassPrecision()\n",
       "  (recall): MulticlassRecall()\n",
       "  (f1): MulticlassF1Score()\n",
       "  (layer_1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (layer_2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (layer_3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minst_model_file = os.path.join(FOLDER_CHEKPOINTS, 'mnist_model.ckpt')\n",
    "model_for_act = MNISTModel.load_from_checkpoint(minst_model_file)\n",
    "model_for_act.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neuron_dataframe(layer_neurons, num_rows, test_loader_act, model_for_act):\n",
    "    # Creación de las columnas para cada neurona\n",
    "    columns = ['Number']\n",
    "    for layer_index, neurons in enumerate(layer_neurons):\n",
    "        columns += [f'Layer{layer_index+1}_Neuron{i+1}' for i in range(neurons)]\n",
    "\n",
    "    # Pre-creación del DataFrame\n",
    "    df = pd.DataFrame(index=range(num_rows), columns=columns)\n",
    "\n",
    "    # Llenar el DataFrame\n",
    "    for idx, batch in enumerate(tqdm(test_loader_act, desc='Running activations')):\n",
    "        x, y = batch\n",
    "        _, r = model_for_act(x, record_activations=True)\n",
    "\n",
    "        # Construir fila para el DataFrame\n",
    "        row = {'Number': y.item()}\n",
    "        for layer_index, neurons in enumerate(layer_neurons):\n",
    "            layer_activation = r[layer_index].cpu().detach().numpy()[0]\n",
    "            for neuron_index in range(neurons):\n",
    "                row[f'Layer{layer_index+1}_Neuron{neuron_index+1}'] = layer_activation[neuron_index]\n",
    "\n",
    "        df.loc[idx] = row\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running activations: 100%|██████████| 10000/10000 [00:05<00:00, 1775.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "layer_neurons = [128, 256, 10]  # Lista con el número de neuronas en cada capa\n",
    "num_rows = len(test_loader_act)  # Número de filas en el DataFrame\n",
    "df = create_neuron_dataframe(layer_neurons, num_rows, test_loader_act, model_for_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Layer1_Neuron1</th>\n",
       "      <th>Layer1_Neuron2</th>\n",
       "      <th>Layer1_Neuron3</th>\n",
       "      <th>Layer1_Neuron4</th>\n",
       "      <th>Layer1_Neuron5</th>\n",
       "      <th>Layer1_Neuron6</th>\n",
       "      <th>Layer1_Neuron7</th>\n",
       "      <th>Layer1_Neuron8</th>\n",
       "      <th>Layer1_Neuron9</th>\n",
       "      <th>...</th>\n",
       "      <th>Layer3_Neuron1</th>\n",
       "      <th>Layer3_Neuron2</th>\n",
       "      <th>Layer3_Neuron3</th>\n",
       "      <th>Layer3_Neuron4</th>\n",
       "      <th>Layer3_Neuron5</th>\n",
       "      <th>Layer3_Neuron6</th>\n",
       "      <th>Layer3_Neuron7</th>\n",
       "      <th>Layer3_Neuron8</th>\n",
       "      <th>Layer3_Neuron9</th>\n",
       "      <th>Layer3_Neuron10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.449542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.147556</td>\n",
       "      <td>-16.15661</td>\n",
       "      <td>-7.710541</td>\n",
       "      <td>-7.271402</td>\n",
       "      <td>-16.029039</td>\n",
       "      <td>-11.763827</td>\n",
       "      <td>-21.846853</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>-14.597517</td>\n",
       "      <td>-10.055029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.981847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.332592</td>\n",
       "      <td>2.098222</td>\n",
       "      <td>0.138524</td>\n",
       "      <td>1.114918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37655</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.453403</td>\n",
       "      <td>-7.174742</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>-5.811386</td>\n",
       "      <td>-15.197481</td>\n",
       "      <td>-7.710469</td>\n",
       "      <td>-7.108836</td>\n",
       "      <td>-16.036268</td>\n",
       "      <td>-7.167393</td>\n",
       "      <td>-18.166189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.556063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702207</td>\n",
       "      <td>1.305601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185222</td>\n",
       "      <td>1.902156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096356</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.221011</td>\n",
       "      <td>-0.01579</td>\n",
       "      <td>-6.059708</td>\n",
       "      <td>-7.541843</td>\n",
       "      <td>-6.083756</td>\n",
       "      <td>-7.373065</td>\n",
       "      <td>-6.17975</td>\n",
       "      <td>-5.144792</td>\n",
       "      <td>-6.342128</td>\n",
       "      <td>-8.537989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>-17.257816</td>\n",
       "      <td>-7.764553</td>\n",
       "      <td>-10.846607</td>\n",
       "      <td>-12.64982</td>\n",
       "      <td>-9.893709</td>\n",
       "      <td>-9.928406</td>\n",
       "      <td>-10.246429</td>\n",
       "      <td>-11.425213</td>\n",
       "      <td>-8.658001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930661</td>\n",
       "      <td>1.347643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907871</td>\n",
       "      <td>1.582013</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.864855</td>\n",
       "      <td>-13.278628</td>\n",
       "      <td>-7.676012</td>\n",
       "      <td>-10.088933</td>\n",
       "      <td>-0.017552</td>\n",
       "      <td>-7.109054</td>\n",
       "      <td>-8.037715</td>\n",
       "      <td>-5.901061</td>\n",
       "      <td>-7.700401</td>\n",
       "      <td>-4.408139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 395 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number Layer1_Neuron1 Layer1_Neuron2 Layer1_Neuron3 Layer1_Neuron4  \\\n",
       "0    7.0       0.449542            0.0            0.0            0.0   \n",
       "1    2.0       1.981847            0.0       2.332592       2.098222   \n",
       "2    1.0       0.556063            0.0       0.702207       1.305601   \n",
       "3    0.0            0.0            0.0       0.922271            0.0   \n",
       "4    4.0            0.0       0.930661       1.347643            0.0   \n",
       "\n",
       "  Layer1_Neuron5 Layer1_Neuron6 Layer1_Neuron7 Layer1_Neuron8 Layer1_Neuron9  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1       0.138524       1.114918            0.0            0.0        0.37655   \n",
       "2            0.0       0.185222       1.902156            0.0       0.096356   \n",
       "3       1.780782            0.0            0.0            0.0        0.51604   \n",
       "4            0.0            0.0            0.0       0.907871       1.582013   \n",
       "\n",
       "   ... Layer3_Neuron1 Layer3_Neuron2 Layer3_Neuron3 Layer3_Neuron4  \\\n",
       "0  ...     -12.147556      -16.15661      -7.710541      -7.271402   \n",
       "1  ...     -10.453403      -7.174742      -0.005843      -5.811386   \n",
       "2  ...     -10.221011       -0.01579      -6.059708      -7.541843   \n",
       "3  ...      -0.000767     -17.257816      -7.764553     -10.846607   \n",
       "4  ...      -7.864855     -13.278628      -7.676012     -10.088933   \n",
       "\n",
       "  Layer3_Neuron5 Layer3_Neuron6 Layer3_Neuron7 Layer3_Neuron8 Layer3_Neuron9  \\\n",
       "0     -16.029039     -11.763827     -21.846853      -0.001201     -14.597517   \n",
       "1     -15.197481      -7.710469      -7.108836     -16.036268      -7.167393   \n",
       "2      -6.083756      -7.373065       -6.17975      -5.144792      -6.342128   \n",
       "3      -12.64982      -9.893709      -9.928406     -10.246429     -11.425213   \n",
       "4      -0.017552      -7.109054      -8.037715      -5.901061      -7.700401   \n",
       "\n",
       "  Layer3_Neuron10  \n",
       "0      -10.055029  \n",
       "1      -18.166189  \n",
       "2       -8.537989  \n",
       "3       -8.658001  \n",
       "4       -4.408139  \n",
       "\n",
       "[5 rows x 395 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save activations csv\n",
    "activation_file = os.path.join(FOLDER_ACTIVATIONS, 'activations_minist_model.csv')\n",
    "df.to_csv(activation_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
