{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "principal_path = '../'\n",
    "if principal_path not in sys.path:\n",
    "    sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from models.MNISTModel import MNISTModel\n",
    "from models.MNISTModelWithBottelNeck import MNISTModelWithBottelNeck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 2024\n",
    "pl.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "LEARING_RATE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "FOLDER_CHEKPOINTS = 'checkpoints'\n",
    "FOLDER_ACTIVATIONS = 'activations'\n",
    "print(f'Using {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_parameters(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    unit_scale = {\n",
    "        '': 1,\n",
    "        'K': 10 ** 3,\n",
    "        'M': 10 ** 6,\n",
    "        'B': 10 ** 9\n",
    "    }\n",
    "    for unit, scale in sorted(unit_scale.items(), key=lambda x: x[1], reverse=True):\n",
    "        if num_params >= scale:\n",
    "            return f'{round(num_params / scale, 1)}{unit}'\n",
    "    return str(num_params)\n",
    "\n",
    "def log_csv(model, model_name, folder = 'csv_logs'):\n",
    "    number_of_parameters = get_number_of_parameters(model)\n",
    "    return CSVLogger(\n",
    "        save_dir=folder,\n",
    "        name=f\"{model_name}_{number_of_parameters}\",\n",
    "    )\n",
    "\n",
    "def log_tensorboard(model, model_name, folder = 'tb_logs'):\n",
    "    number_of_parameters = get_number_of_parameters(model)\n",
    "    return TensorBoardLogger(\n",
    "        save_dir=folder,\n",
    "        name=f\"{model_name}_{number_of_parameters}\",\n",
    "    )\n",
    "\n",
    "def log_wandb(model, model_name, folder = 'wandb_logs'):\n",
    "    number_of_parameters = get_number_of_parameters(model)\n",
    "    return WandbLogger(\n",
    "        save_dir=folder,\n",
    "        name=f\"{model_name}_{number_of_parameters}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=BATCH_SIZE, num_workers=4):\n",
    "    # Transformaciones para los datos\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # Carga de datos de entrenamiento\n",
    "    mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
    "    \n",
    "    # División entre entrenamiento y validación\n",
    "    train_size = int(0.8 * len(mnist_train))\n",
    "    val_size = len(mnist_train) - train_size\n",
    "    mnist_train, mnist_val = random_split(mnist_train, [train_size, val_size])\n",
    "\n",
    "    # DataLoader para entrenamiento y validación\n",
    "    train_loader = DataLoader(mnist_train, batch_size=batch_size, num_workers=num_workers, shuffle=True, persistent_workers=True)\n",
    "    val_loader = DataLoader(mnist_val, batch_size=batch_size, num_workers=num_workers, shuffle=False, persistent_workers=True)\n",
    "\n",
    "    # Carga de datos de test\n",
    "    mnist_test = MNIST(os.getcwd(), train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=batch_size, num_workers=num_workers, persistent_workers=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel(lr=LEARING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggers = [\n",
    "    #log_tensorboard(model, 'MLP'),\n",
    "    log_csv(model, 'MLP'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params\n",
      "--------------------------------------------------\n",
      "0 | train_acc | MulticlassAccuracy  | 0     \n",
      "1 | val_acc   | MulticlassAccuracy  | 0     \n",
      "2 | test_acc  | MulticlassAccuracy  | 0     \n",
      "3 | precision | MulticlassPrecision | 0     \n",
      "4 | recall    | MulticlassRecall    | 0     \n",
      "5 | f1        | MulticlassF1Score   | 0     \n",
      "6 | layer_1   | Linear              | 100 K \n",
      "7 | layer_2   | Linear              | 33.0 K\n",
      "8 | layer_3   | Linear              | 2.6 K \n",
      "--------------------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: |          | 0/? [00:00<?, ?it/s]                                 Failed to save model graph: 'ExperimentWriter' object has no attribute 'add_graph'\n",
      "Epoch 0: 100%|██████████| 750/750 [00:03<00:00, 211.45it/s, v_num=1, train_loss=0.202, train_acc=0.922, val_loss=0.168, val_acc=0.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to save weights histogram: 'ExperimentWriter' object has no attribute 'add_histogram'\n",
      "Epoch 0: 100%|██████████| 750/750 [00:03<00:00, 211.07it/s, v_num=1, train_loss=0.202, train_acc=0.922, val_loss=0.168, val_acc=0.950]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS, logger=loggers)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:00<00:00, 219.24it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "           f1               0.9464820027351379\n",
      "        precision           0.9515219926834106\n",
      "         recall             0.9501408934593201\n",
      "        test_acc            0.9519000053405762\n",
      "        test_loss           0.15671443939208984\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.15671443939208984,\n",
       "  'test_acc': 0.9519000053405762,\n",
       "  'precision': 0.9515219926834106,\n",
       "  'recall': 0.9501408934593201,\n",
       "  'f1': 0.9464820027351379}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save checkpoint\n",
    "file = os.path.join(FOLDER_CHEKPOINTS, 'mnist_model.ckpt')\n",
    "trainer.save_checkpoint(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTModelWithBottelNeck(\n",
      "  (train_acc): MulticlassAccuracy()\n",
      "  (val_acc): MulticlassAccuracy()\n",
      "  (test_acc): MulticlassAccuracy()\n",
      "  (precision): MulticlassPrecision()\n",
      "  (recall): MulticlassRecall()\n",
      "  (f1): MulticlassF1Score()\n",
      "  (layer_1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (layer_2): Linear(in_features=256, out_features=784, bias=True)\n",
      "  (layer_3): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "bottel_neck_model = MNISTModelWithBottelNeck(lr=LEARING_RATE)\n",
    "print(bottel_neck_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggers = [\n",
    "    #log_tensorboard(bottel_neck_model, 'BottelNeck'),\n",
    "    log_csv(bottel_neck_model, 'BottelNeck'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: tb_logs\\BottelNeck_410.3K\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params\n",
      "--------------------------------------------------\n",
      "0 | train_acc | MulticlassAccuracy  | 0     \n",
      "1 | val_acc   | MulticlassAccuracy  | 0     \n",
      "2 | test_acc  | MulticlassAccuracy  | 0     \n",
      "3 | precision | MulticlassPrecision | 0     \n",
      "4 | recall    | MulticlassRecall    | 0     \n",
      "5 | f1        | MulticlassF1Score   | 0     \n",
      "6 | layer_1   | Linear              | 200 K \n",
      "7 | layer_2   | Linear              | 201 K \n",
      "8 | layer_3   | Linear              | 7.9 K \n",
      "--------------------------------------------------\n",
      "410 K     Trainable params\n",
      "0         Non-trainable params\n",
      "410 K     Total params\n",
      "1.641     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d3ea5206924a49aa2a1852ab683689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b57f329522419ea6142c67d8417abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2b563e52bb4f73a3d90b6447343a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS, logger=log_tensorboard(bottel_neck_model, 'BottelNeck'))\n",
    "trainer.fit(bottel_neck_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9fd376057d4ac99c8c7068727f2c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            f1             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9550154209136963     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.958906352519989     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9597558379173279     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9606000185012817     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.11922504752874374    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           f1            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9550154209136963    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.958906352519989    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9597558379173279    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9606000185012817    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.11922504752874374   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.11922504752874374,\n",
       "  'test_acc': 0.9606000185012817,\n",
       "  'precision': 0.958906352519989,\n",
       "  'recall': 0.9597558379173279,\n",
       "  'f1': 0.9550154209136963}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(bottel_neck_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save checkpoint\n",
    "file = os.path.join(FOLDER_CHEKPOINTS, 'mnist_model_bottel_neck.ckpt')\n",
    "trainer.save_checkpoint(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_activations():\n",
    "    # load only one image of the test set\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_test = MNIST(os.getcwd(), train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=1, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "test_loader_act = load_data_for_activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\migue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\utilities\\migration\\utils.py:49: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.1.2, which is newer than your current Lightning version: v2.0.1\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MNISTModel(\n",
       "  (train_acc): MulticlassAccuracy()\n",
       "  (val_acc): MulticlassAccuracy()\n",
       "  (test_acc): MulticlassAccuracy()\n",
       "  (precision): MulticlassPrecision()\n",
       "  (recall): MulticlassRecall()\n",
       "  (f1): MulticlassF1Score()\n",
       "  (layer_1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (layer_2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (layer_3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minst_model_file = os.path.join(FOLDER_CHEKPOINTS, 'mnist_model.ckpt')\n",
    "model_for_act = MNISTModel.load_from_checkpoint(minst_model_file)\n",
    "model_for_act.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neuron_dataframe(layer_neurons, num_rows, test_loader_act, model_for_act):\n",
    "    # Creación de las columnas para cada neurona\n",
    "    columns = ['Number']\n",
    "    for layer_index, neurons in enumerate(layer_neurons):\n",
    "        columns += [f'layer_{layer_index+1}_Neuron{i+1}' for i in range(neurons)]\n",
    "\n",
    "    # Pre-creación del DataFrame\n",
    "    df = pd.DataFrame(index=range(num_rows), columns=columns)\n",
    "\n",
    "    # Llenar el DataFrame\n",
    "    for idx, batch in enumerate(tqdm(test_loader_act, desc='Running activations')):\n",
    "        x, y = batch\n",
    "        _, r = model_for_act(x, record_activations=True)\n",
    "\n",
    "        # Construir fila para el DataFrame\n",
    "        row = {'Number': y.item()}\n",
    "        for layer_index, neurons in enumerate(layer_neurons):\n",
    "            layer_activation = r[layer_index].cpu().detach().numpy()[0]\n",
    "            for neuron_index in range(neurons):\n",
    "                row[f'layer_{layer_index+1}_Neuron{neuron_index+1}'] = layer_activation[neuron_index]\n",
    "\n",
    "        df.loc[idx] = row\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running activations: 100%|██████████| 10000/10000 [00:06<00:00, 1432.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "layer_neurons = [128, 256, 10]  # Lista con el número de neuronas en cada capa\n",
    "num_rows = len(test_loader_act)  # Número de filas en el DataFrame\n",
    "df = create_neuron_dataframe(layer_neurons, num_rows, test_loader_act, model_for_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>layer_1_Neuron1</th>\n",
       "      <th>layer_1_Neuron2</th>\n",
       "      <th>layer_1_Neuron3</th>\n",
       "      <th>layer_1_Neuron4</th>\n",
       "      <th>layer_1_Neuron5</th>\n",
       "      <th>layer_1_Neuron6</th>\n",
       "      <th>layer_1_Neuron7</th>\n",
       "      <th>layer_1_Neuron8</th>\n",
       "      <th>layer_1_Neuron9</th>\n",
       "      <th>...</th>\n",
       "      <th>layer_3_Neuron1</th>\n",
       "      <th>layer_3_Neuron2</th>\n",
       "      <th>layer_3_Neuron3</th>\n",
       "      <th>layer_3_Neuron4</th>\n",
       "      <th>layer_3_Neuron5</th>\n",
       "      <th>layer_3_Neuron6</th>\n",
       "      <th>layer_3_Neuron7</th>\n",
       "      <th>layer_3_Neuron8</th>\n",
       "      <th>layer_3_Neuron9</th>\n",
       "      <th>layer_3_Neuron10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.449542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.147557</td>\n",
       "      <td>-16.156612</td>\n",
       "      <td>-7.710542</td>\n",
       "      <td>-7.271403</td>\n",
       "      <td>-16.029039</td>\n",
       "      <td>-11.763829</td>\n",
       "      <td>-21.846853</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>-14.597518</td>\n",
       "      <td>-10.05503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.981847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.332592</td>\n",
       "      <td>2.098222</td>\n",
       "      <td>0.138524</td>\n",
       "      <td>1.114918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.37655</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.453403</td>\n",
       "      <td>-7.174742</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>-5.811386</td>\n",
       "      <td>-15.197481</td>\n",
       "      <td>-7.71047</td>\n",
       "      <td>-7.108836</td>\n",
       "      <td>-16.036266</td>\n",
       "      <td>-7.167393</td>\n",
       "      <td>-18.166189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.556063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.702207</td>\n",
       "      <td>1.305601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185222</td>\n",
       "      <td>1.902156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096356</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.221011</td>\n",
       "      <td>-0.01579</td>\n",
       "      <td>-6.059709</td>\n",
       "      <td>-7.541844</td>\n",
       "      <td>-6.083756</td>\n",
       "      <td>-7.373065</td>\n",
       "      <td>-6.179751</td>\n",
       "      <td>-5.144793</td>\n",
       "      <td>-6.342128</td>\n",
       "      <td>-8.53799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>-17.257816</td>\n",
       "      <td>-7.764552</td>\n",
       "      <td>-10.846606</td>\n",
       "      <td>-12.64982</td>\n",
       "      <td>-9.893708</td>\n",
       "      <td>-9.928405</td>\n",
       "      <td>-10.246428</td>\n",
       "      <td>-11.425212</td>\n",
       "      <td>-8.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930661</td>\n",
       "      <td>1.347643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907871</td>\n",
       "      <td>1.582013</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.864855</td>\n",
       "      <td>-13.278628</td>\n",
       "      <td>-7.676012</td>\n",
       "      <td>-10.088933</td>\n",
       "      <td>-0.017552</td>\n",
       "      <td>-7.109054</td>\n",
       "      <td>-8.037715</td>\n",
       "      <td>-5.901061</td>\n",
       "      <td>-7.700401</td>\n",
       "      <td>-4.408139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 395 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number layer_1_Neuron1 layer_1_Neuron2 layer_1_Neuron3 layer_1_Neuron4  \\\n",
       "0    7.0        0.449542             0.0             0.0             0.0   \n",
       "1    2.0        1.981847             0.0        2.332592        2.098222   \n",
       "2    1.0        0.556063             0.0        0.702207        1.305601   \n",
       "3    0.0             0.0             0.0        0.922271             0.0   \n",
       "4    4.0             0.0        0.930661        1.347643             0.0   \n",
       "\n",
       "  layer_1_Neuron5 layer_1_Neuron6 layer_1_Neuron7 layer_1_Neuron8  \\\n",
       "0             0.0             0.0             0.0             0.0   \n",
       "1        0.138524        1.114918             0.0             0.0   \n",
       "2             0.0        0.185222        1.902156             0.0   \n",
       "3        1.780782             0.0             0.0             0.0   \n",
       "4             0.0             0.0             0.0        0.907871   \n",
       "\n",
       "  layer_1_Neuron9  ... layer_3_Neuron1 layer_3_Neuron2 layer_3_Neuron3  \\\n",
       "0             0.0  ...      -12.147557      -16.156612       -7.710542   \n",
       "1         0.37655  ...      -10.453403       -7.174742       -0.005843   \n",
       "2        0.096356  ...      -10.221011        -0.01579       -6.059709   \n",
       "3         0.51604  ...       -0.000767      -17.257816       -7.764552   \n",
       "4        1.582013  ...       -7.864855      -13.278628       -7.676012   \n",
       "\n",
       "  layer_3_Neuron4 layer_3_Neuron5 layer_3_Neuron6 layer_3_Neuron7  \\\n",
       "0       -7.271403      -16.029039      -11.763829      -21.846853   \n",
       "1       -5.811386      -15.197481        -7.71047       -7.108836   \n",
       "2       -7.541844       -6.083756       -7.373065       -6.179751   \n",
       "3      -10.846606       -12.64982       -9.893708       -9.928405   \n",
       "4      -10.088933       -0.017552       -7.109054       -8.037715   \n",
       "\n",
       "  layer_3_Neuron8 layer_3_Neuron9 layer_3_Neuron10  \n",
       "0       -0.001201      -14.597518        -10.05503  \n",
       "1      -16.036266       -7.167393       -18.166189  \n",
       "2       -5.144793       -6.342128         -8.53799  \n",
       "3      -10.246428      -11.425212           -8.658  \n",
       "4       -5.901061       -7.700401        -4.408139  \n",
       "\n",
       "[5 rows x 395 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save activations csv\n",
    "activation_file = os.path.join(FOLDER_ACTIVATIONS, 'activations_minist_model.csv')\n",
    "df.to_csv(activation_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTModelWithBottelNeck(\n",
      "  (train_acc): MulticlassAccuracy()\n",
      "  (val_acc): MulticlassAccuracy()\n",
      "  (test_acc): MulticlassAccuracy()\n",
      "  (precision): MulticlassPrecision()\n",
      "  (recall): MulticlassRecall()\n",
      "  (f1): MulticlassF1Score()\n",
      "  (layer_1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (layer_2): Linear(in_features=256, out_features=784, bias=True)\n",
      "  (layer_3): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_bottelnet_file = os.path.join(FOLDER_CHEKPOINTS, 'mnist_model_bottel_neck.ckpt')\n",
    "model_bottelnet_for_act = MNISTModelWithBottelNeck.load_from_checkpoint(model_bottelnet_file)\n",
    "model_bottelnet_for_act.eval()\n",
    "print(model_bottelnet_for_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running activations: 100%|██████████| 10000/10000 [00:11<00:00, 895.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Number layer_1_Neuron1 layer_1_Neuron2 layer_1_Neuron3 layer_1_Neuron4  \\\n",
      "0    7.0        0.263696             0.0             0.0             0.0   \n",
      "1    2.0             0.0             0.0             0.0             0.0   \n",
      "2    1.0        0.644008        0.217488             0.0        0.049021   \n",
      "3    0.0             0.0             0.0             0.0             0.0   \n",
      "4    4.0             0.0             0.0         0.06545        0.255205   \n",
      "\n",
      "  layer_1_Neuron5 layer_1_Neuron6 layer_1_Neuron7 layer_1_Neuron8  \\\n",
      "0        0.141333             0.0             0.0        0.285032   \n",
      "1             0.0        0.596677        1.227557        1.123563   \n",
      "2             0.0        0.514683        0.404544             0.0   \n",
      "3             0.0        0.648394             0.0        1.429647   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "  layer_1_Neuron9  ... layer_3_Neuron1 layer_3_Neuron2 layer_3_Neuron3  \\\n",
      "0             0.0  ...      -15.224203      -12.899465        -7.78768   \n",
      "1        0.497353  ...      -10.328734        -6.15697       -0.002433   \n",
      "2        0.026223  ...       -9.683863       -0.014177       -6.245885   \n",
      "3             0.0  ...       -0.001296      -12.824494       -8.546868   \n",
      "4        0.376863  ...      -10.019976      -11.619699       -9.525784   \n",
      "\n",
      "  layer_3_Neuron4 layer_3_Neuron5 layer_3_Neuron6 layer_3_Neuron7  \\\n",
      "0       -5.763442      -16.093821      -12.746031      -23.097193   \n",
      "1       -8.562925      -17.386738      -11.050374      -10.695917   \n",
      "2       -8.168837        -5.74015       -8.440497       -7.465419   \n",
      "3      -11.030286      -10.846011        -9.23065       -8.384238   \n",
      "4       -10.67384       -0.206108       -9.737457        -9.42208   \n",
      "\n",
      "  layer_3_Neuron8 layer_3_Neuron9 layer_3_Neuron10  \n",
      "0        -0.00411      -14.059266        -7.524554  \n",
      "1      -15.268203       -9.936504       -19.288153  \n",
      "2       -5.103272       -6.443178        -9.007465  \n",
      "3        -9.24935      -10.858867         -7.38443  \n",
      "4       -5.411996       -8.526304        -1.707576  \n",
      "\n",
      "[5 rows x 1051 columns]\n"
     ]
    }
   ],
   "source": [
    "layer_neurons = [256,784,10]\n",
    "num_rows = len(test_loader_act)\n",
    "\n",
    "df = create_neuron_dataframe(layer_neurons, num_rows, test_loader_act, model_bottelnet_for_act)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "activation_file = os.path.join(FOLDER_ACTIVATIONS, 'activations_minist_model_bottel_neck.csv')\n",
    "df.to_csv(activation_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
