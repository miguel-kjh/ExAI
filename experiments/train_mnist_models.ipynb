{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "principal_path = '../'\n",
    "if principal_path not in sys.path:\n",
    "    sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from models.MNISTModel import MNISTModel\n",
    "from models.MNISTModelWithBottelNeck import MNISTModelWithBottelNeck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 2024\n",
    "pl.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "LEARING_RATE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "FOLDER_CHEKPOINTS = 'checkpoints'\n",
    "FOLDER_ACTIVATIONS = 'activations'\n",
    "print(f'Using {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_parameters(model):\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    unit_scale = {\n",
    "        '': 1,\n",
    "        'K': 10 ** 3,\n",
    "        'M': 10 ** 6,\n",
    "        'B': 10 ** 9\n",
    "    }\n",
    "    for unit, scale in sorted(unit_scale.items(), key=lambda x: x[1], reverse=True):\n",
    "        if num_params >= scale:\n",
    "            return f'{round(num_params / scale, 1)}{unit}'\n",
    "    return str(num_params)\n",
    "\n",
    "def log_csv(model, model_name, folder = 'csv_logs'):\n",
    "    number_of_parameters = get_number_of_parameters(model)\n",
    "    return CSVLogger(\n",
    "        save_dir=folder,\n",
    "        name=f\"{model_name}_{number_of_parameters}\",\n",
    "    )\n",
    "\n",
    "def log_tensorboard(model, model_name, folder = 'tb_logs'):\n",
    "    number_of_parameters = get_number_of_parameters(model)\n",
    "    return TensorBoardLogger(\n",
    "        save_dir=folder,\n",
    "        name=f\"{model_name}_{number_of_parameters}\",\n",
    "    )\n",
    "\n",
    "def log_wandb(model, model_name, folder = 'wandb_logs'):\n",
    "    number_of_parameters = get_number_of_parameters(model)\n",
    "    return WandbLogger(\n",
    "        save_dir=folder,\n",
    "        name=f\"{model_name}_{number_of_parameters}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=BATCH_SIZE, num_workers=4):\n",
    "    # Transformaciones para los datos\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    # Carga de datos de entrenamiento\n",
    "    mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)\n",
    "    \n",
    "    # División entre entrenamiento y validación\n",
    "    train_size = int(0.8 * len(mnist_train))\n",
    "    val_size = len(mnist_train) - train_size\n",
    "    mnist_train, mnist_val = random_split(mnist_train, [train_size, val_size])\n",
    "\n",
    "    # DataLoader para entrenamiento y validación\n",
    "    train_loader = DataLoader(mnist_train, batch_size=batch_size, num_workers=num_workers, shuffle=True, persistent_workers=True)\n",
    "    val_loader = DataLoader(mnist_val, batch_size=batch_size, num_workers=num_workers, shuffle=False, persistent_workers=True)\n",
    "\n",
    "    # Carga de datos de test\n",
    "    mnist_test = MNIST(os.getcwd(), train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=batch_size, num_workers=num_workers, persistent_workers=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel(lr=LEARING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggers = [\n",
    "    log_tensorboard(model, 'MLP'),\n",
    "    log_csv(model, 'MLP'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params\n",
      "--------------------------------------------------\n",
      "0 | train_acc | MulticlassAccuracy  | 0     \n",
      "1 | val_acc   | MulticlassAccuracy  | 0     \n",
      "2 | test_acc  | MulticlassAccuracy  | 0     \n",
      "3 | precision | MulticlassPrecision | 0     \n",
      "4 | recall    | MulticlassRecall    | 0     \n",
      "5 | f1        | MulticlassF1Score   | 0     \n",
      "6 | layer_1   | Linear              | 100 K \n",
      "7 | layer_2   | Linear              | 33.0 K\n",
      "8 | layer_3   | Linear              | 2.6 K \n",
      "--------------------------------------------------\n",
      "136 K     Trainable params\n",
      "0         Non-trainable params\n",
      "136 K     Total params\n",
      "0.544     Total estimated model params size (MB)\n",
      "c:\\Users\\migue\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\fabric\\loggers\\csv_logs.py:188: UserWarning: Experiment logs directory csv_logs\\MLP_136.1K\\version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23513ce9d65047d294ff28c469fc6002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4d36285c114ca59a8ab0cb68847e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149f0b200e04470f8c6e3279b9e6ffb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e77f34b67b7478898a09088ab2622bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f74c7203f14be68465beb4696883d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b19f13d7404ee08d8bb8d91435f33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6ae4c4837a4155a68526061f1df32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS, logger=loggers)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f66cee060c4025ac0e9ecde40855c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            f1             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9707237482070923     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9733837842941284     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9732210040092468     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9753000140190125     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.08122822642326355    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           f1            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9707237482070923    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9733837842941284    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9732210040092468    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9753000140190125    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.08122822642326355   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.08122822642326355,\n",
       "  'test_acc': 0.9753000140190125,\n",
       "  'precision': 0.9733837842941284,\n",
       "  'recall': 0.9732210040092468,\n",
       "  'f1': 0.9707237482070923}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save checkpoint\n",
    "file = os.path.join(FOLDER_CHEKPOINTS, 'mnist_model.ckpt')\n",
    "trainer.save_checkpoint(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottel_neck_model = MNISTModelWithBottelNeck(lr=LEARING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggers = [\n",
    "    log_tensorboard(bottel_neck_model, 'BottelNeck'),\n",
    "    log_csv(bottel_neck_model, 'BottelNeck'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params\n",
      "--------------------------------------------------\n",
      "0 | train_acc | MulticlassAccuracy  | 0     \n",
      "1 | val_acc   | MulticlassAccuracy  | 0     \n",
      "2 | test_acc  | MulticlassAccuracy  | 0     \n",
      "3 | precision | MulticlassPrecision | 0     \n",
      "4 | recall    | MulticlassRecall    | 0     \n",
      "5 | f1        | MulticlassF1Score   | 0     \n",
      "6 | layer_1   | Linear              | 200 K \n",
      "7 | layer_2   | Linear              | 32.9 K\n",
      "8 | layer_3   | Linear              | 33.0 K\n",
      "9 | layer_4   | Linear              | 2.6 K \n",
      "--------------------------------------------------\n",
      "269 K     Trainable params\n",
      "0         Non-trainable params\n",
      "269 K     Total params\n",
      "1.078     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec931b1d62fe4a0ab6d1c42edc3ec54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63741b26738402d9f7580947ab1450a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ed672bb68e47619fc46960745af2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d89f94214f48b2b4b28f3fe2657e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723c64edccb045ddb09ca2edb49d42cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4e2d83066b411e82fdb9810395931d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf43ea5a13b44962a7aef7d3497dffa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS, logger=log_tensorboard(bottel_neck_model, 'BottelNeck'))\n",
    "trainer.fit(bottel_neck_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865808cb633c46078638e70e6ee8ee66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">            f1             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9632332921028137     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9670910835266113     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9658780097961426     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9684000015258789     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.10720314830541611    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m           f1            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9632332921028137    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9670910835266113    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9658780097961426    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9684000015258789    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.10720314830541611   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.10720314830541611,\n",
       "  'test_acc': 0.9684000015258789,\n",
       "  'precision': 0.9670910835266113,\n",
       "  'recall': 0.9658780097961426,\n",
       "  'f1': 0.9632332921028137}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(bottel_neck_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save checkpoint\n",
    "file = os.path.join(FOLDER_CHEKPOINTS, 'mnist_model_bottel_neck.ckpt')\n",
    "trainer.save_checkpoint(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_activations():\n",
    "    # load only one image of the test set\n",
    "    transform = transforms.ToTensor()\n",
    "    mnist_test = MNIST(os.getcwd(), train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(mnist_test, batch_size=1, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "test_loader_act = load_data_for_activations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTModel(\n",
       "  (train_acc): MulticlassAccuracy()\n",
       "  (val_acc): MulticlassAccuracy()\n",
       "  (test_acc): MulticlassAccuracy()\n",
       "  (precision): MulticlassPrecision()\n",
       "  (recall): MulticlassRecall()\n",
       "  (f1): MulticlassF1Score()\n",
       "  (layer_1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (layer_2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (layer_3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minst_model_file = os.path.join(FOLDER_CHEKPOINTS, 'mnist_model.ckpt')\n",
    "model_for_act = MNISTModel.load_from_checkpoint(minst_model_file)\n",
    "model_for_act.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neuron_dataframe(layer_neurons, num_rows, test_loader_act, model_for_act):\n",
    "    # Creación de las columnas para cada neurona\n",
    "    columns = ['Number']\n",
    "    for layer_index, neurons in enumerate(layer_neurons):\n",
    "        columns += [f'Layer{layer_index+1}_Neuron{i+1}' for i in range(neurons)]\n",
    "\n",
    "    # Pre-creación del DataFrame\n",
    "    df = pd.DataFrame(index=range(num_rows), columns=columns)\n",
    "\n",
    "    # Llenar el DataFrame\n",
    "    for idx, batch in enumerate(tqdm(test_loader_act, desc='Running activations')):\n",
    "        x, y = batch\n",
    "        _, r = model_for_act(x, record_activations=True)\n",
    "\n",
    "        # Construir fila para el DataFrame\n",
    "        row = {'Number': y.item()}\n",
    "        for layer_index, neurons in enumerate(layer_neurons):\n",
    "            layer_activation = r[layer_index].cpu().detach().numpy()[0]\n",
    "            for neuron_index in range(neurons):\n",
    "                row[f'Layer{layer_index+1}_Neuron{neuron_index+1}'] = layer_activation[neuron_index]\n",
    "\n",
    "        df.loc[idx] = row\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running activations: 100%|██████████| 10000/10000 [00:08<00:00, 1141.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso\n",
    "layer_neurons = [128, 256, 10]  # Lista con el número de neuronas en cada capa\n",
    "num_rows = len(test_loader_act)  # Número de filas en el DataFrame\n",
    "df = create_neuron_dataframe(layer_neurons, num_rows, test_loader_act, model_for_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Layer1_Neuron1</th>\n",
       "      <th>Layer1_Neuron2</th>\n",
       "      <th>Layer1_Neuron3</th>\n",
       "      <th>Layer1_Neuron4</th>\n",
       "      <th>Layer1_Neuron5</th>\n",
       "      <th>Layer1_Neuron6</th>\n",
       "      <th>Layer1_Neuron7</th>\n",
       "      <th>Layer1_Neuron8</th>\n",
       "      <th>Layer1_Neuron9</th>\n",
       "      <th>...</th>\n",
       "      <th>Layer3_Neuron1</th>\n",
       "      <th>Layer3_Neuron2</th>\n",
       "      <th>Layer3_Neuron3</th>\n",
       "      <th>Layer3_Neuron4</th>\n",
       "      <th>Layer3_Neuron5</th>\n",
       "      <th>Layer3_Neuron6</th>\n",
       "      <th>Layer3_Neuron7</th>\n",
       "      <th>Layer3_Neuron8</th>\n",
       "      <th>Layer3_Neuron9</th>\n",
       "      <th>Layer3_Neuron10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.92348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.595833</td>\n",
       "      <td>-14.188923</td>\n",
       "      <td>-8.905098</td>\n",
       "      <td>-10.092788</td>\n",
       "      <td>-22.101274</td>\n",
       "      <td>-15.535633</td>\n",
       "      <td>-29.975979</td>\n",
       "      <td>-0.00018</td>\n",
       "      <td>-14.806216</td>\n",
       "      <td>-13.204277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.26403</td>\n",
       "      <td>2.359124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.33489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.821211</td>\n",
       "      <td>0.531313</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.110266</td>\n",
       "      <td>-12.353317</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-15.05283</td>\n",
       "      <td>-29.732016</td>\n",
       "      <td>-22.506277</td>\n",
       "      <td>-20.308481</td>\n",
       "      <td>-23.745291</td>\n",
       "      <td>-13.633943</td>\n",
       "      <td>-34.262554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59751</td>\n",
       "      <td>0.420798</td>\n",
       "      <td>0.433036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574497</td>\n",
       "      <td>1.608488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053121</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.868408</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>-9.372239</td>\n",
       "      <td>-12.341898</td>\n",
       "      <td>-9.200323</td>\n",
       "      <td>-9.77616</td>\n",
       "      <td>-9.750698</td>\n",
       "      <td>-8.316074</td>\n",
       "      <td>-7.506509</td>\n",
       "      <td>-14.401055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.198138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.564893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>-13.230165</td>\n",
       "      <td>-9.013961</td>\n",
       "      <td>-16.788416</td>\n",
       "      <td>-12.716939</td>\n",
       "      <td>-12.95721</td>\n",
       "      <td>-9.12406</td>\n",
       "      <td>-12.553201</td>\n",
       "      <td>-12.449683</td>\n",
       "      <td>-8.221807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.628678</td>\n",
       "      <td>0.627652</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.683038</td>\n",
       "      <td>-15.717505</td>\n",
       "      <td>-15.271838</td>\n",
       "      <td>-20.522961</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>-14.758453</td>\n",
       "      <td>-13.264597</td>\n",
       "      <td>-13.595921</td>\n",
       "      <td>-12.924339</td>\n",
       "      <td>-7.03157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 395 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Number Layer1_Neuron1 Layer1_Neuron2 Layer1_Neuron3 Layer1_Neuron4  \\\n",
       "0    7.0            0.0            0.0            0.0            0.0   \n",
       "1    2.0            0.0            0.0        2.26403       2.359124   \n",
       "2    1.0            0.0        0.59751       0.420798       0.433036   \n",
       "3    0.0            0.0            0.0       0.270113            0.0   \n",
       "4    4.0            0.0            0.0       0.984886            0.0   \n",
       "\n",
       "  Layer1_Neuron5 Layer1_Neuron6 Layer1_Neuron7 Layer1_Neuron8 Layer1_Neuron9  \\\n",
       "0            0.0            0.0            0.0        0.92348            0.0   \n",
       "1            0.0        1.33489            0.0       0.821211       0.531313   \n",
       "2            0.0       0.574497       1.608488            0.0       0.053121   \n",
       "3       1.198138            0.0            0.0       2.564893            0.0   \n",
       "4            0.0            0.0            0.0       1.628678       0.627652   \n",
       "\n",
       "   ... Layer3_Neuron1 Layer3_Neuron2 Layer3_Neuron3 Layer3_Neuron4  \\\n",
       "0  ...     -16.595833     -14.188923      -8.905098     -10.092788   \n",
       "1  ...     -21.110266     -12.353317      -0.000006      -15.05283   \n",
       "2  ...     -15.868408      -0.001101      -9.372239     -12.341898   \n",
       "3  ...      -0.000514     -13.230165      -9.013961     -16.788416   \n",
       "4  ...     -14.683038     -15.717505     -15.271838     -20.522961   \n",
       "\n",
       "  Layer3_Neuron5 Layer3_Neuron6 Layer3_Neuron7 Layer3_Neuron8 Layer3_Neuron9  \\\n",
       "0     -22.101274     -15.535633     -29.975979       -0.00018     -14.806216   \n",
       "1     -29.732016     -22.506277     -20.308481     -23.745291     -13.633943   \n",
       "2      -9.200323       -9.77616      -9.750698      -8.316074      -7.506509   \n",
       "3     -12.716939      -12.95721       -9.12406     -12.553201     -12.449683   \n",
       "4      -0.000891     -14.758453     -13.264597     -13.595921     -12.924339   \n",
       "\n",
       "  Layer3_Neuron10  \n",
       "0      -13.204277  \n",
       "1      -34.262554  \n",
       "2      -14.401055  \n",
       "3       -8.221807  \n",
       "4        -7.03157  \n",
       "\n",
       "[5 rows x 395 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save activations csv\n",
    "activation_file = os.path.join(FOLDER_ACTIVATIONS, 'activations_minist_model.csv')\n",
    "df.to_csv(activation_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
